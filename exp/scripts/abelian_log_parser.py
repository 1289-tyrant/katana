##########################################
# To parse log files generated by abelian.
# Author: Gurbinder Gill
# Email: gurbinder533@gmail.com
#########################################

import re
import os
import sys, getopt
import csv
import numpy

######## NOTES:
# All time values are in sec.

#CommandLine : /work/02982/ggill0/Distributed_latest/build_dist_hetero/release_new_gcc/exp/apps/hsssp/bfs_gen /work/02982/ggill0/Distributed_latest/inputs/pagerank/Galois/scalefree/NEW/rmat16-2e25-a=0.57-b=0.19-c=0.19-d=.05.gr -maxIterations=10000 -srcNodeId=0 -verify=0 -t=15

#Hostname : c453-401.stampede.tacc.utexas.edu

#Threads : 15

#Hosts : 32

#Runs : 3

#[31]STATTYPE,LOOP,CATEGORY,n,sum,T0,T1,T2,T3,T4,T5,T6,T7,T8,T9,T10,T11,T12,T13,T14
#[31]STAT,(NULL),RecvBytes,15,402945176,402945176,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),RecvNum,15,2480,2480,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SYNC_PULL_BFS_0_1,15,4614,4614,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SYNC_PULL_BFS_0_2,15,4629,4629,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SYNC_PULL_BFS_0_3,15,4616,4616,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SYNC_PULL_BFS_0_4,15,4619,4619,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SYNC_PULL_BFS_1_1,15,4623,4623,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SYNC_PULL_BFS_1_2,15,4617,4617,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SYNC_PULL_BFS_1_3,15,4612,4612,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SYNC_PULL_BFS_1_4,15,4624,4624,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SYNC_PULL_BFS_2_1,15,4625,4625,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SYNC_PULL_BFS_2_2,15,4633,4633,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SYNC_PULL_BFS_2_3,15,4631,4631,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SYNC_PULL_BFS_2_4,15,4626,4626,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SYNC_PULL_InitializeGraph_0_1,15,160818,160818,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SYNC_PULL_InitializeGraph_1_1,15,4656,4656,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SYNC_PUSH_BFS_0_1,15,10967,10967,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SYNC_PUSH_BFS_0_2,15,9759,9759,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SYNC_PUSH_BFS_0_3,15,9766,9766,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SYNC_PUSH_BFS_0_4,15,9763,9763,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SYNC_PUSH_BFS_1_1,15,10953,10953,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SYNC_PUSH_BFS_1_2,15,9774,9774,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SYNC_PUSH_BFS_1_3,15,9760,9760,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SYNC_PUSH_BFS_1_4,15,9772,9772,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SYNC_PUSH_BFS_2_1,15,10956,10956,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SYNC_PUSH_BFS_2_2,15,9762,9762,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SYNC_PUSH_BFS_2_3,15,9756,9756,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SYNC_PUSH_BFS_2_4,15,9755,9755,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SendBytes,15,223858996,223858996,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),SendNum,15,2108,2108,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),TIMER_0,15,58743,58743,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),TIMER_1,15,58745,58745,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),TIMER_2,15,58751,58751,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),TIMER_GRAPH_INIT,15,156169,156169,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),TIMER_HG_INIT,15,17422,17422,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[31]STAT,(NULL),TIMER_TOTAL,15,359146,359146,0,0,0,0,0,0,0,0,0,0,0,0,0,0

#[13]STAT,PageRank,Commits,15,6377945,277895,324235,482281,296898,572496,295661,311751,434026,421630,445072,711824,444553,408666,535821,415136
#[13]STAT,PageRank,Conflicts,15,3167,196,281,296,210,438,288,203,304,135,128,213,111,106,152,106
#[13]STAT,PageRank,Iterations,15,6381112,278091,324516,482577,297108,572934,295949,311954,434330,421765,445200,712037,444664,408772,535973,415242
#[13]STAT,PageRank,Pushes,15,26999,3263,1940,2700,3747,2227,1977,2536,2264,694,895,720,1220,864,1006,946

def match_timers(fileName, benchmark, forHost, numRuns, numThreads):

  mean_timer = 0.0;
  recvNum_total = 0
  recvBytes_total = 0
  sendNum_total = 0
  sendBytes_total = 0
  sync_pull_avg_time_total = 0.0;
  sync_push_avg_time_total = 0.0;
  graph_init_time = 0
  hg_init_time = 0
  total_time = 0
  thousand = 1000.0

  timer_regex = re.compile(r'\[' + re.escape(forHost) + r'\]STAT,\(NULL\),TIMER_(\d*),' + re.escape(numThreads) + r',(\d*),(\d*).*')

  log_data = open(fileName).read()

  timers = re.findall(timer_regex, log_data)
  print timers

  for timer in timers:
    mean_timer = mean_timer + float(timer[2])

  if(len(timers) > 0):
    mean_timer /= len(timers)
    mean_timer /= thousand

  print "Mean time: ", mean_timer

  if(benchmark == "cc"):
    benchmark = "ConnectedComp"

  ## SYNC_PULL and SYNC_PUSH total average over runs.
  num_iterations = 0
  for i in range(0, int(numRuns)):
    # find sync_pull
    sync_pull_regex = re.compile(r'\[' + re.escape(forHost) + r'\]STAT,\(NULL\),SYNC_PULL_(?i)' + re.escape(benchmark) + r'\w*_' + re.escape(str(i)) + r'_(\d*),\d*,(\d*),(\d*).*')
    sync_pull_lines = re.findall(sync_pull_regex, log_data)
    num_iterations = len(sync_pull_lines);
    for j in range (0, len(sync_pull_lines)):
      sync_pull_avg_time_total += float(sync_pull_lines[j][2])

    # find sync_push
    sync_push_regex = re.compile(r'\[' + re.escape(forHost) + r'\]STAT,\(NULL\),SYNC_PUSH_(?i)' + re.escape(benchmark) + r'\w*_'+ re.escape(str(i)) + r'_(\d*),\d*,(\d*),(\d*).*')
    sync_push_lines = re.findall(sync_push_regex, log_data)

    if(num_iterations == 0):
      num_iterations = len(sync_push_lines)

    for j in range (0, len(sync_push_lines)):
      sync_push_avg_time_total += float(sync_push_lines[j][2])

  sync_pull_avg_time_total /= int(numRuns)
  sync_pull_avg_time_total /= thousand
  sync_push_avg_time_total /= int(numRuns)
  sync_push_avg_time_total /= thousand

  ## sendBytes and recvBytes.
  #recvBytes_regex = re.compile(r'\[' + re.escape(forHost) + r'\]STAT,\(NULL\),RecvBytes,\d*,(\d*),(\d*),.*')
  #recvBytes_search = recvBytes_regex.search(log_data)
  #if recvBytes_search is not None:
     #recvBytes_total = float(recvBytes_search.group(1))/int(numRuns)

  #sendBytes_regex = re.compile(r'\[' + re.escape(forHost) + r'\]STAT,\(NULL\),SendBytes,\d*,(\d*),(\d*),.*')
  #sendBytes_search = sendBytes_regex.search(log_data)
  #if sendBytes_search is not None:
    #sendBytes_total = float(sendBytes_search.group(1))/int(numRuns)

  ## sendNum and recvNum.
  #recvNum_regex = re.compile(r'\[' + re.escape(forHost) + r'\]STAT,\(NULL\),RecvNum,\d*,(\d*),(\d*),.*')
  #recvNum_search = recvNum_regex.search(log_data)
  #if recvNum_search is not None:
    #recvNum_total = float(recvNum_search.group(1))/int(numRuns)

  #sendNum_regex = re.compile(r'\[' + re.escape(forHost) + r'\]STAT,\(NULL\),SendNum,\d*,(\d*),(\d*),.*')
  #sendNum_search = sendNum_regex.search(log_data)
  #if sendNum_search is not None:
    #sendNum_total = float(sendNum_search.group(1))/int(numRuns)

  ## Get Graph_init, HG_init, total
  timer_graph_init_regex = re.compile(r'\[' + re.escape(forHost) + r'\]STAT,\(NULL\),TIMER_GRAPH_INIT,' + re.escape(numThreads) + r',(\d*),(\d*).*')
  timer_hg_init_regex = re.compile(r'\[' + re.escape(forHost) + r'\]STAT,\(NULL\),TIMER_HG_INIT,' + re.escape(numThreads) + r',(\d*),(\d*).*')
  timer_total_regex = re.compile(r'\[' + re.escape(forHost) + r'\]STAT,\(NULL\),TIMER_TOTAL,' + re.escape(numThreads) + r',(\d*),(\d*).*')


  timer_graph_init = timer_graph_init_regex.search(log_data)
  timer_hg_init = timer_hg_init_regex.search(log_data)
  timer_total = timer_total_regex.search(log_data)

  if timer_graph_init is not None:
    graph_init_time = float(timer_graph_init.group(1))
    graph_init_time /= thousand

  if timer_hg_init is not None:
    hg_init_time = float(timer_hg_init.group(1))
    hg_init_time /= thousand

  if timer_total is not None:
    total_time = float(timer_total.group(1))
    total_time /= thousand

  #[13]STAT,PageRank,Commits,15,6377945,277895,324235,482281,296898,572496,295661,311751,434026,421630,445072,711824,444553,408666,535821,415136
  #[13]STAT,PageRank,Conflicts,15,3167,196,281,296,210,438,288,203,304,135,128,213,111,106,152,106
  #[13]STAT,PageRank,Iterations,15,6381112,278091,324516,482577,297108,572934,295949,311954,434330,421765,445200,712037,444664,408772,535973,415242
  #[13]STAT,PageRank,Pushes,15,26999,3263,1940,2700,3747,2227,1977,2536,2264,694,895,720,1220,864,1006,946

  ## Get Commits, Conflicts, Iterations, Pushes for worklist versions:
  commits_search = re.compile(r'\[' + re.escape(forHost) + r'\]STAT,(?i)' + re.escape(benchmark) + '\w*,Commits,' + re.escape(numThreads) + r',(\d*),(\d*).*').search(log_data)
  conflicts_search = re.compile(r'\[' + re.escape(forHost) + r'\]STAT,(?i)' + re.escape(benchmark) + r'\w*,Conflicts,' + re.escape(numThreads) + r',(\d*),(\d*).*').search(log_data)
  iterations_search = re.compile(r'\[' + re.escape(forHost) + r'\]STAT,(?i)' + re.escape(benchmark) + r'\w*,Iterations,' + re.escape(numThreads) + r',(\d*),(\d*).*').search(log_data)
  pushes_search = re.compile(r'\[' + re.escape(forHost) + r'\]STAT,(?i)' + re.escape(benchmark) + r'\w*,Pushes,' + re.escape(numThreads) + r',(\d*),(\d*).*').search(log_data)

  commits    = 0
  conflicts  = 0
  iterations = 0
  pushes     = 0
  if commits_search is not None:
    commits = int(commits_search.group(1))
    commits /= int(numRuns)
  if conflicts_search is not None:
    conflicts = int(conflicts_search.group(1))
    conflicts /= int(numRuns)
  if iterations_search is not None:
    iterations = int(iterations_search.group(1))
    iterations /= int(numRuns)
  if pushes_search is not None:
    pushes = int(pushes_search.group(1))
    pushes /= int(numRuns)


  #return mean_timer,graph_init_time,hg_init_time,total_time,sync_pull_avg_time_total,sync_push_avg_time_total,recvNum_total,recvBytes_total,sendNum_total,sendBytes_total,commits,conflicts,iterations, pushes
  return mean_timer,graph_init_time,hg_init_time,total_time,sync_pull_avg_time_total,sync_push_avg_time_total,num_iterations,commits,conflicts,iterations, pushes


def sendRecv_bytes_all(fileName, benchmark, total_hosts, numRuns, numThreads):
  sendBytes_list = [0]*256 #Max host number is 256
  recvBytes_list = [0]*256 #Max host number is 256

  log_data = open(fileName).read()

  ## sendBytes and recvBytes.
  total_SendBytes = 0;
  for host in range(0,int(total_hosts)):
    sendBytes_regex = re.compile(r'\[' + re.escape(str(host)) + r'\]STAT,\(NULL\),SendBytes,\d*,(\d*),(\d*),.*')
    sendBytes_search = sendBytes_regex.search(log_data)
    if sendBytes_search is not None:
      sendBytes_list[host] = float(sendBytes_search.group(1))/int(numRuns)

  total_SendBytes = sum(sendBytes_list)

  total_RecvBytes = 0;
  for host in range(0,int(total_hosts)):
    recvBytes_regex = re.compile(r'\[' + re.escape(str(host)) + r'\]STAT,\(NULL\),RecvBytes,\d*,(\d*),(\d*),.*')
    recvBytes_search = recvBytes_regex.search(log_data)
    if recvBytes_search is not None:
       recvBytes_list[host] = float(recvBytes_search.group(1))/int(numRuns)

  total_RecvBytes = sum(recvBytes_list)
  return total_SendBytes, sendBytes_list



#6]STAT,(NULL),SEND_BYTES_SYNC_PULL_REPLY_BFS_0_1,15,121980,121980,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[6]STAT,(NULL),SEND_BYTES_SYNC_PULL_REPLY_BFS_0_2,15,121980,121980,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[6]STAT,(NULL),SEND_BYTES_SYNC_PULL_REPLY_BFS_0_3,15,121980,121980,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[6]STAT,(NULL),SEND_BYTES_SYNC_PULL_REPLY_BFS_0_4,15,121980,121980,0,0,0,0,0,0,0,0,0,0,0,0,0,0

#[7]STAT,(NULL),GhostNodes_from_0,15,35892,35892,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),GhostNodes_from_1,15,18635,18635,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),GhostNodes_from_2,15,18743,18743,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),GhostNodes_from_3,15,10125,10125,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),GhostNodes_from_4,15,18842,18842,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),GhostNodes_from_5,15,10230,10230,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),GhostNodes_from_6,15,10163,10163,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),GhostNodes_from_7,15,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),RecvBytes,15,22083788,22083788,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),RecvNum,15,392,392,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SEND_BYTES_SYNC_PULL_BFS_0_1,15,1471812,1471812,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SEND_BYTES_SYNC_PULL_BFS_0_2,15,1471812,1471812,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SEND_BYTES_SYNC_PULL_BFS_0_3,15,1471812,1471812,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SEND_BYTES_SYNC_PULL_BFS_0_4,15,1471812,1471812,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SEND_BYTES_SYNC_PULL_BFS_1_1,15,1471812,1471812,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SEND_BYTES_SYNC_PULL_BFS_1_2,15,1471812,1471812,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SEND_BYTES_SYNC_PULL_BFS_1_3,15,1471812,1471812,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SEND_BYTES_SYNC_PULL_BFS_1_4,15,1471812,1471812,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SEND_BYTES_SYNC_PULL_BFS_2_1,15,1471812,1471812,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SEND_BYTES_SYNC_PULL_BFS_2_2,15,1471812,1471812,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SEND_BYTES_SYNC_PULL_BFS_2_3,15,1471812,1471812,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SEND_BYTES_SYNC_PULL_BFS_2_4,15,1471812,1471812,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SEND_BYTES_SYNC_PULL_InitializeGraph_0_1,15,2943792,2943792,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SEND_BYTES_SYNC_PULL_InitializeGraph_1_1,15,1471896,1471896,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SYNC_PULL_BFS_0_1,15,525,525,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SYNC_PULL_BFS_0_2,15,152,152,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SYNC_PULL_BFS_0_3,15,340,340,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SYNC_PULL_BFS_0_4,15,340,340,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SYNC_PULL_BFS_1_1,15,539,539,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SYNC_PULL_BFS_1_2,15,153,153,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SYNC_PULL_BFS_1_3,15,340,340,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SYNC_PULL_BFS_1_4,15,341,341,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SYNC_PULL_BFS_2_1,15,539,539,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SYNC_PULL_BFS_2_2,15,152,152,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SYNC_PULL_BFS_2_3,15,340,340,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SYNC_PULL_BFS_2_4,15,341,341,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SYNC_PULL_InitializeGraph_0_1,15,23082,23082,0,0,0,0,0,0,0,0,0,0,0,0,0,0
#[7]STAT,(NULL),SYNC_PULL_InitializeGraph_1_1,15,47,47,0,0,0,0,0,0,0,0,0,0,0,0,0,0
def sendBytes_syncOnly(fileName, benchmark, total_hosts, numRuns, numThreads):
  sendBytes_total_list = [0]*256 #Max host number is 256
  sendBytes_pull_sync_list = [0]*256 #Max host number is 256
  sendBytes_push_sync_list = [0]*256 #Max host number is 256
  sendBytes_pull_sync_reply_list = [0]*256 #Max host number is 256

  log_data = open(fileName).read()

  ## sendBytes from sync_pull.
  total_SendBytes_pull_sync = 0;
  for host in range(0,int(total_hosts)):
    sendBytes_sync_pull_regex = re.compile(r'\[' + re.escape(str(host)) + r'\]STAT,\(NULL\),SEND_BYTES_SYNC_PULL_(?i)'+ re.escape(benchmark) + r'_0_\d*,\d*,(\d*),(\d*),.*')
    sendBytes_sync_pull_lines = re.findall(sendBytes_sync_pull_regex, log_data)
    print sendBytes_sync_pull_lines

    if len(sendBytes_sync_pull_lines) > 0:
      sendBytes_pull_sync_list[host] = float(sendBytes_sync_pull_lines[0][0]) * len(sendBytes_sync_pull_lines)
      sendBytes_total_list[host] += sendBytes_pull_sync_list[host]
      print "-------> : ", host , " val : " , sendBytes_pull_sync_list[host]

  total_SendBytes_pull_sync = sum(sendBytes_pull_sync_list)

  ## sendBytes from sync_pull_reply.
  total_SendBytes_pull_reply = 0;
  for host in range(0,int(total_hosts)):
    sendBytes_sync_pull_reply_regex = re.compile(r'\[' + re.escape(str(host)) + r'\]STAT,\(NULL\),SEND_BYTES_SYNC_PULL_REPLY_(?i)'+ re.escape(benchmark) + r'_0_\d*,\d*,(\d*),(\d*),.*')
    sendBytes_sync_pull_reply_lines = re.findall(sendBytes_sync_pull_reply_regex, log_data)
    print sendBytes_sync_pull_reply_lines

    if len(sendBytes_sync_pull_reply_lines) > 0:
      sendBytes_pull_sync_reply_list[host] = float(sendBytes_sync_pull_reply_lines[0][0]) * len(sendBytes_sync_pull_reply_lines)
      sendBytes_total_list[host] += sendBytes_pull_sync_reply_list[host]
      #print "-------> : ", host , " val : " , sendBytes_pull_sync_reply_list[host]

  total_SendBytes_pull_reply = sum(sendBytes_pull_sync_reply_list)

  #[2]STAT,(NULL),SEND_BYTES_SYNC_PUSH_BFS_0_0,15,33738828,33738828,0,0,0,0,0,0,0,0,0,0,0,0,0,0
   ## sendBytes from sync_push.
  total_SendBytes_push_sync = 0;
  for host in range(0,int(total_hosts)):
    sendBytes_sync_push_regex = re.compile(r'\[' + re.escape(str(host)) + r'\]STAT,\(NULL\),SEND_BYTES_SYNC_PUSH_(?i)'+ re.escape(benchmark) + r'_0_\d*,\d*,(\d*),(\d*),.*')
    sendBytes_sync_push_lines = re.findall(sendBytes_sync_push_regex, log_data)
    print sendBytes_sync_push_lines

    if len(sendBytes_sync_push_lines) > 0:
      sendBytes_push_sync_list[host] = float(sendBytes_sync_push_lines[0][0]) * len(sendBytes_sync_push_lines)
      sendBytes_total_list[host] += sendBytes_push_sync_list[host]
      #print "-------> : ", host , " val : " , sendBytes_push_sync_list[host]

  total_SendBytes_push_sync = sum(sendBytes_push_sync_list)

  total_SendBytes = total_SendBytes_pull_sync + total_SendBytes_pull_reply + total_SendBytes_push_sync

  return total_SendBytes, total_SendBytes_pull_sync, total_SendBytes_pull_reply, total_SendBytes_push_sync, sendBytes_total_list


def build_master_ghost_matrix(fileName, benchmark, partition, total_hosts, numRuns, numThreads):
  #[1]STAT,(NULL),GhostNodes_from_1,15,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
  log_data = open(fileName).read()
  if partition == "edge-cut":
    GhostNodes_array = numpy.zeros((int(total_hosts), int(total_hosts)))
    for host in range(0, int(total_hosts)):
      ghost_from_re = re.compile(r'\[' + re.escape(str(host)) + r'\]STAT,\(NULL\),GhostNodes_from_(\d*),\d*,(\d*),.*')
      ghost_from_lines = re.findall(ghost_from_re, log_data)
      if(len(ghost_from_lines) > 0):
        for line in ghost_from_lines:
          GhostNodes_array[host][int(line[0])] = int(line[1])
    return GhostNodes_array
  #[1]STAT,(NULL),SLAVE_NODES_FROM_0,15,21693895,21693895,0,0,0,0,0,0,0,0,0,0,0,0,0,0
  elif partition == "vertex-cut":
    SlaveNodes_array = numpy.zeros((int(total_hosts), int(total_hosts)))
    for host in range(0, int(total_hosts)):
      slave_from_re = re.compile(r'\[' + re.escape(str(host)) + r'\]STAT,\(NULL\),SLAVE_NODES_FROM_(\d*),\d*,(\d*),.*')
      slave_from_lines = re.findall(slave_from_re, log_data)
      if(len(slave_from_lines) > 0):
        for line in slave_from_lines:
          SlaveNodes_array[host][int(line[0])] = int(line[1])
    return SlaveNodes_array



def get_basicInfo(fileName):

  hostNum_regex = re.compile(r'Hosts\s:\s(\d*)')
  cmdLine_regex = re.compile(r'CommandLine\s:\s(.*)')
  threads_regex = re.compile(r'Threads\s:\s(\d*)')
  runs_regex = re.compile(r'Runs\s:\s(\d*)')

  log_data = open(fileName).read()

  hostNum    = ''
  cmdLine    = ''
  threads    = ''
  runs       = ''
  benchmark  = ''
  algo_type  = ''
  cut_type   = ''
  input_graph = ''

  hostNum_search = hostNum_regex.search(log_data)
  if hostNum_search is not None:
    hostNum = hostNum_search.group(1)

  cmdLine_search = cmdLine_regex.search(log_data)
  if cmdLine_search is not None:
    cmdLine = cmdLine_search.group(1)

  threads_search = threads_regex.search(log_data)
  if threads_search is not None:
    threads = threads_search.group(1)

  runs_search    = runs_regex.search(log_data)
  if runs_search is not None:
    runs = runs_search.group(1)

  split_cmdLine_algo = cmdLine.split()[0].split("/")[-1].split("_")
  benchmark, algo_type, cut_type =  split_cmdLine_algo

  split_cmdLine_input = cmdLine.split()[1].split("/")
  input_graph = split_cmdLine_input[-1]

  return hostNum, cmdLine, threads, runs, benchmark, algo_type, cut_type, input_graph

def format_str(col):
  max_len = 0
  for c in col:
    if max_len < len(str(c)):
      max_len = len(str(c))
  return max_len

def main(argv):
  inputFile = ''
  forHost = '0'
  outputFile = 'LOG_output.csv'
  try:
    opts, args = getopt.getopt(argv,"hi:n:o:",["ifile=","node=","ofile="])
  except getopt.GetoptError:
    print 'abelian_log_parser.py -i <inputFile> -n <hostNumber 0 to hosts - 1 > -o <outputFile>'
    sys.exit(2)
  for opt, arg in opts:
    if opt == '-h':
      print 'abelian_log_parser.py -i <inputFile>'
      sys.exit()
    elif opt in ("-i", "--ifile"):
      inputFile = arg
    elif opt in ("-n", "--node"):
      forHost = arg
    elif opt in ("-o", "--ofile"):
      outputFile = arg

  print 'Input file is : ', inputFile
  print 'Data for host : ', forHost

  hostNum, cmdLine, threads, runs, benchmark, algo_type, cut_type, input_graph = get_basicInfo(inputFile)

  #shorten the graph names:
  if input_graph == "twitter-ICWSM10-component_withRandomWeights.transpose.gr" or input_graph == "twitter-ICWSM10-component-transpose.gr":
    input_graph = "twitterIC_trans.gr"
  elif input_graph == "twitter-ICWSM10-component_withRandomWeights.gr" or input_graph == "twitter-ICWSM10-component.gr":
    input_graph = "twitterIC.gr"
  elif input_graph == "USA-road-d.USA-trans.gr":
    input_graph = "USA-trans.gr"
  elif input_graph == "USA-road-d.USA.gr":
    input_graph = "USA.gr"
  elif input_graph == "rmat16-2e25-a=0.57-b=0.19-c=0.19-d=.05.transpose.gr":
    input_graph = "rmat_trans.gr"
  elif input_graph == "rmat16-2e25-a=0.57-b=0.19-c=0.19-d=.05.gr":
    input_graph = "rmat.gr"


  print 'Hosts : ', hostNum , ' CmdLine : ', cmdLine, ' Threads : ', threads , ' Runs : ', runs, ' benchmark :' , benchmark , ' algo_type :', algo_type, ' cut_type : ', cut_type, ' input_graph : ', input_graph

  data = match_timers(inputFile, benchmark, forHost, runs, threads)
  #total_SendBytes, sendBytes_list = sendRecv_bytes_all(inputFile, benchmark, hostNum, runs, threads)
  total_SendBytes, total_SendBytes_pull_sync, total_SendBytes_pull_reply, total_SendBytes_push_sync, sendBytes_list = sendBytes_syncOnly(inputFile, benchmark, hostNum, runs, threads)
  print data

  output_str = benchmark + ',' + 'abelian'  + ',' + hostNum  + ',' + threads  + ',' + input_graph  + ',' + algo_type  + ',' + cut_type

  #for d in data:
    #output_str += ','
    #output_str += str(d)
  print output_str


  #header_csv_str = "benchmark,platform,host,threads,input,variant,partition,mean_time,graph_init_time,hg_init_time,total_time,sync_pull_avg_time,sync_push_avg_time,recvNum,recvBytes,sendNum,sendBytes,commits,conflicts,iterations,pushes"
  header_csv_str = "benchmark,platform,host,threads,input,variant,partition,mean_time,graph_init_time,hg_init_time,total_time,sync_pull_avg_time,sync_push_avg_time,converge_iterations,commits,conflicts,iterations,pushes,total_sendBytes, total_sendBytes_pull_sync, total_sendBytes_pull_reply, total_sendBytes_push_sync"

  for i in range(0,256):
    header_csv_str += ","
    header_csv_str += ("SB_" + str(i))

  header_csv_list = header_csv_str.split(',')
  #if outputFile is empty add the header to the file
  try:
    if os.path.isfile(outputFile) is False:
      fd_outputFile = open(outputFile, 'wb')
      wr = csv.writer(fd_outputFile, quoting=csv.QUOTE_NONE, lineterminator='\n')
      wr.writerow(header_csv_list)
      fd_outputFile.close()
      print "Adding header to the empty file."
    else:
      print "outputFile : ", outputFile, " exists, results will be appended to it."
  except OSError:
    print "Error in outfile opening\n"

  data_list = list(data)
  data_list.extend((total_SendBytes, total_SendBytes_pull_sync, total_SendBytes_pull_reply, total_SendBytes_push_sync))
  complete_data = output_str.split(",") + data_list + list(sendBytes_list)
  fd_outputFile = open(outputFile, 'a')
  wr = csv.writer(fd_outputFile, quoting=csv.QUOTE_NONE, lineterminator='\n')
  wr.writerow(complete_data)
  fd_outputFile.close()


  ## Write ghost and slave nodes to a file.
  ghost_array = build_master_ghost_matrix(inputFile, benchmark, cut_type, hostNum, runs, threads)
  ghostNodes_file = outputFile + "_" + cut_type
  fd_ghostNodes_file = open(ghostNodes_file, 'ab')
  fd_ghostNodes_file.write("\n--------------------------------------------------------------\n")
  fd_ghostNodes_file.write("\nHosts : " + hostNum + "\nInputFile : "+ inputFile + "\nBenchmark: " + benchmark + "\nPartition: " + cut_type + "\n\n")
  numpy.savetxt(fd_ghostNodes_file, ghost_array, delimiter=',', fmt='%d')
  fd_ghostNodes_file.write("\n--------------------------------------------------------------\n")
  fd_ghostNodes_file.close()


if __name__ == "__main__":
  main(sys.argv[1:])

